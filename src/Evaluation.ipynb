{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building index from 0‚ùóÔ∏è\n",
      "Initialized connection to Firebase\n",
      "Downloading object from rag-outputs-pdf: RAGDOC Firebase Service Account.json to credentials/RAGDOC Firebase Service Account.json\n",
      "Firebase app already initialized\n",
      "Set up connection to Firebase Database (default) in project ragdoc-3a072\n",
      "\n",
      "Getting all documents for Tipos de aprendizaje.pdf from Firebase\n",
      "Getting all documents from collection parsed-documents_data\n",
      "Limiting to 50 documents\n",
      "Getting documents from the following file:  Tipos de aprendizaje.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ixchelgarciaa./Documents/Learning/UE/Tesis/RAG/.venv/lib/python3.11/site-packages/google/cloud/firestore_v1/base_collection.py:300: UserWarning: Detected filter using positional arguments. Prefer using the 'filter' keyword argument instead.\n",
      "  return query.where(field_path, op_string, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting documents to LlamaIndex documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 132229.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion successful!\n",
      "Downloaded 50 documents for Tipos de aprendizaje.pdf from Firebase\n",
      "\n",
      "Getting all documents for Algoritmo de Bayes Ingenuo.pdf from Firebase\n",
      "Getting all documents from collection parsed-documents_data\n",
      "Limiting to 50 documents\n",
      "Getting documents from the following file:  Algoritmo de Bayes Ingenuo.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting documents to LlamaIndex documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 81316.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion successful!\n",
      "Downloaded 50 documents for Algoritmo de Bayes Ingenuo.pdf from Firebase\n",
      "\n",
      "Getting all documents for Conceptos de evaluaci√≥n.pdf from Firebase\n",
      "Getting all documents from collection parsed-documents_data\n",
      "Limiting to 50 documents\n",
      "Getting documents from the following file:  Conceptos de evaluaci√≥n.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting documents to LlamaIndex documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 158156.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion successful!\n",
      "Downloaded 50 documents for Conceptos de evaluaci√≥n.pdf from Firebase\n",
      "Downloaded 150 documents from Firebase\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "Initializing pinecone...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(409)\n",
      "Reason: Conflict\n",
      "HTTP response headers: HTTPHeaderDict({'content-type': 'text/plain; charset=utf-8', 'access-control-allow-origin': '*', 'vary': 'origin,access-control-request-method,access-control-request-headers', 'access-control-expose-headers': '*', 'x-pinecone-api-version': '2024-07', 'X-Cloud-Trace-Context': 'e1c9c6600a2db4a786b2214e540af833', 'Date': 'Mon, 16 Sep 2024 02:15:57 GMT', 'Server': 'Google Frontend', 'Content-Length': '85', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\n",
      "HTTP response body: {\"error\":{\"code\":\"ALREADY_EXISTS\",\"message\":\"Resource  already exists\"},\"status\":409}\n",
      "\n",
      "Finished setting up pinecone index: {'dimension': 1024,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 744}},\n",
      " 'total_vector_count': 744}\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "Initializing embedding model...\n",
      "Finished setting up embedding model: model_name='BAAI/bge-m3' embed_batch_size=10 callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x31bf9a050> num_workers=None max_length=8192 normalize=True query_instruction=None text_instruction=None cache_folder=None\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "Initializing llm model...\n",
      "Finished setting up llm model: callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x31bf9a050> system_prompt=None messages_to_prompt=<function messages_to_prompt at 0x3030e56c0> completion_to_prompt=<function default_completion_to_prompt at 0x30638ac00> output_parser=None pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'> query_wrapper_prompt=None model='gpt-4o-mini' temperature=0.1 max_tokens=1000 logprobs=False top_logprobs=0 additional_kwargs={} max_retries=3 timeout=60.0 default_headers={} reuse_client=True api_key='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' api_base='https://api.openai.com/v1' api_version='' strict=False\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "Finished setting up dependencies. üéâ\n",
      "\n",
      "Building index...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a8fa19a67934ab0b8536cfd84c9f23b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bdc87bd77b34f94ab3ce60740f13b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2f65cf2e4a744d893319139860e1701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished building index üöÄ\n",
      "\n",
      "{'dimension': 1024,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 744}},\n",
      " 'total_vector_count': 744}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:text_qa_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will receive a question in Spanish.\n",
      "The question is based in the given context, since it contains the theory on which the question must be answered.\n",
      "Context information is below.\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query in Spanish.\n",
      "Query: {query_str}\n",
      "Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:refine_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original query is as follows: {query_str}\n",
      "We have provided an existing answer: {existing_answer}\n",
      "We have the opportunity to refine the existing answer (only if needed) with some more context below.\n",
      "------------\n",
      "{context_msg}\n",
      "------------\n",
      "Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\n",
      "Refined Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n",
      "Not building index from 0...\n",
      "Initializing pinecone...\n",
      "(409)\n",
      "Reason: Conflict\n",
      "HTTP response headers: HTTPHeaderDict({'content-type': 'text/plain; charset=utf-8', 'access-control-allow-origin': '*', 'vary': 'origin,access-control-request-method,access-control-request-headers', 'access-control-expose-headers': '*', 'x-pinecone-api-version': '2024-07', 'X-Cloud-Trace-Context': '2a0cc86fba3d1c1d7204ef3c06430d30', 'Date': 'Mon, 16 Sep 2024 02:16:10 GMT', 'Server': 'Google Frontend', 'Content-Length': '85', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\n",
      "HTTP response body: {\"error\":{\"code\":\"ALREADY_EXISTS\",\"message\":\"Resource  already exists\"},\"status\":409}\n",
      "\n",
      "Finished setting up pinecone index: {'dimension': 1024,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 749}},\n",
      " 'total_vector_count': 749}\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "Initializing node parser...\n",
      "Initializing postprocessors for nodes...\n",
      "Finished setting up node parser: include_metadata=True include_prev_next_rel=True callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x34f9271d0> id_func=<function default_id_func at 0x302d62fc0> sentence_splitter=<function split_by_sentence_tokenizer.<locals>.<lambda> at 0x33dc1ca40> window_size=4 window_metadata_key='window' original_text_metadata_key='text'\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "Loading index from storage...\n",
      "\n",
      "Finished building index üöÄ\n",
      "\n",
      "{'dimension': 1024,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 749}},\n",
      " 'total_vector_count': 749}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:text_qa_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will receive a question in Spanish.\n",
      "The question is based in the given context, since it contains the theory on which the question must be answered.\n",
      "Context information is below.\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query in Spanish.\n",
      "Query: {query_str}\n",
      "Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:refine_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original query is as follows: {query_str}\n",
      "We have provided an existing answer: {existing_answer}\n",
      "We have the opportunity to refine the existing answer (only if needed) with some more context below.\n",
      "------------\n",
      "{context_msg}\n",
      "------------\n",
      "Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\n",
      "Refined Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not building index from 0...\n",
      "Initializing pinecone...\n",
      "(409)\n",
      "Reason: Conflict\n",
      "HTTP response headers: HTTPHeaderDict({'content-type': 'text/plain; charset=utf-8', 'access-control-allow-origin': '*', 'vary': 'origin,access-control-request-method,access-control-request-headers', 'access-control-expose-headers': '*', 'x-pinecone-api-version': '2024-07', 'X-Cloud-Trace-Context': '7763e807abd304423dc4ea3142dfc5d5', 'Date': 'Mon, 16 Sep 2024 02:16:12 GMT', 'Server': 'Google Frontend', 'Content-Length': '85', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\n",
      "HTTP response body: {\"error\":{\"code\":\"ALREADY_EXISTS\",\"message\":\"Resource  already exists\"},\"status\":409}\n",
      "\n",
      "Finished setting up pinecone index: {'dimension': 1024,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 749}},\n",
      " 'total_vector_count': 749}\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "Initializing node parser...\n",
      "Finished setting up node parser: include_metadata=True include_prev_next_rel=True callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x34f8f38d0> id_func=None chunk_sizes=[2048, 512, 128] node_parser_ids=['chunk_size_2048', 'chunk_size_512', 'chunk_size_128'] node_parser_map={'chunk_size_2048': SentenceSplitter(include_metadata=True, include_prev_next_rel=True, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x34f8f38d0>, id_func=<function default_id_func at 0x302d62fc0>, chunk_size=2048, chunk_overlap=20, separator=' ', paragraph_separator='\\n\\n\\n', secondary_chunking_regex='[^,.;„ÄÇÔºüÔºÅ]+[,.;„ÄÇÔºüÔºÅ]?'), 'chunk_size_512': SentenceSplitter(include_metadata=True, include_prev_next_rel=True, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x34f8f38d0>, id_func=<function default_id_func at 0x302d62fc0>, chunk_size=512, chunk_overlap=20, separator=' ', paragraph_separator='\\n\\n\\n', secondary_chunking_regex='[^,.;„ÄÇÔºüÔºÅ]+[,.;„ÄÇÔºüÔºÅ]?'), 'chunk_size_128': SentenceSplitter(include_metadata=True, include_prev_next_rel=True, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x34f8f38d0>, id_func=<function default_id_func at 0x302d62fc0>, chunk_size=128, chunk_overlap=20, separator=' ', paragraph_separator='\\n\\n\\n', secondary_chunking_regex='[^,.;„ÄÇÔºüÔºÅ]+[,.;„ÄÇÔºüÔºÅ]?')}\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "Loading index from storage...\n",
      "\n",
      "Finished building index üöÄ\n",
      "\n",
      "{'dimension': 1024,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 749}},\n",
      " 'total_vector_count': 749}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:text_qa_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will receive a question in Spanish.\n",
      "The question is based in the given context, since it contains the theory on which the question must be answered.\n",
      "Context information is below.\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query in Spanish.\n",
      "Query: {query_str}\n",
      "Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:refine_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original query is as follows: {query_str}\n",
      "We have provided an existing answer: {existing_answer}\n",
      "We have the opportunity to refine the existing answer (only if needed) with some more context below.\n",
      "------------\n",
      "{context_msg}\n",
      "------------\n",
      "Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\n",
      "Refined Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAGs to evaluate:  [<__main__.RAG object at 0x3493ae710>, <__main__.SentenceRetrievalRag object at 0x34f910f50>, <__main__.AutoMergingRetrievalRag object at 0x34f904490>]\n"
     ]
    }
   ],
   "source": [
    "%run RAG.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading object from rag-outputs-pdf: evaluation_questions.txt to evaluation/evaluation_questions.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation questions have been downloaded in the following path: evaluation/evaluation_questions.txt\n"
     ]
    }
   ],
   "source": [
    "eval_questions_path = rags_for_eval[0].get_evaluation_questions()\n",
    "eval_questions = []\n",
    "with open(eval_questions_path, 'r') as file:\n",
    "    for line in file:\n",
    "        item = line.strip()\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.apps.custom import instrument\n",
    "from trulens.core import TruSession\n",
    "\n",
    "session = TruSession()\n",
    "session.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trulens_app(rag, feedbacks:list):\n",
    "  \"\"\"\n",
    "  Get trulens app for a given rag and feedbacks.\n",
    "\n",
    "  Args:\n",
    "    rag: RAG object.\n",
    "    feedbacks: List of feedbacks.\n",
    "\n",
    "  Returns:\n",
    "    trulens app.\n",
    "  \"\"\"\n",
    "  from trulens.apps.custom import TruCustomApp\n",
    "\n",
    "  return TruCustomApp(\n",
    "    rag,\n",
    "    app_name=\"RAG\",\n",
    "    app_version=rag.name,\n",
    "    feedbacks=feedbacks,\n",
    "  )\n",
    "  \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "def build_trulens_recorder(rag):\n",
    "  \"\"\"\n",
    "  Build trulens recorder for a given rag, setting the feedbacks functions and building the recorder app.\n",
    "\n",
    "  Args:\n",
    "    rag: RAG object.\n",
    "\n",
    "  Returns:\n",
    "    trulens recorder app.\n",
    "  \"\"\"\n",
    "  from trulens.providers.openai import OpenAI\n",
    "  from trulens.core import Feedback\n",
    "  from trulens.core import Select\n",
    "  import numpy as np\n",
    "\n",
    "  provider = OpenAI(model_engine=\"gpt-4o-mini\")\n",
    "\n",
    "  # Define a groundedness feedback function\n",
    "  f_groundedness = Feedback(\n",
    "          provider.groundedness_measure_with_cot_reasons, name=\"Groundedness\"\n",
    "      ).on(\n",
    "        Select.RecordCalls.retrieve.rets.collect()\n",
    "      ).on_output()\n",
    "\n",
    "  # Question/answer relevance between overall question and answer.\n",
    "  f_answer_relevance = Feedback(\n",
    "      provider.relevance_with_cot_reasons, name=\"Answer Relevance\"\n",
    "  ).on_input(\n",
    "  ).on_output()\n",
    "\n",
    "  # Question/statement relevance between question and each context chunk.\n",
    "  f_context_relevance = Feedback(\n",
    "          provider.context_relevance_with_cot_reasons, name=\"Context Relevance\"\n",
    "      ).on_input(\n",
    "      ).on(\n",
    "        Select.RecordCalls.retrieve.rets[:]\n",
    "      ).aggregate(np.mean)\n",
    "  \n",
    "\n",
    "  feedbacks = [f_groundedness, f_answer_relevance, f_context_relevance]\n",
    "\n",
    "  return get_trulens_app(rag, feedbacks)\n",
    "\n",
    "\n",
    "def eval_rags(rags:list, questions:list):\n",
    "  \"\"\"\n",
    "  Evaluate a list of rags for a list of questions.\n",
    "\n",
    "  Args:\n",
    "    rags: List of RAG objects.\n",
    "    questions: List of questions for evaluation.\n",
    "\n",
    "  Returns:\n",
    "    None\n",
    "  \"\"\"\n",
    "  from tqdm import tqdm\n",
    "\n",
    "  for r in rags:\n",
    "    print(\"Evaluating: \", r.name)\n",
    "    tru_query_engine_recorder = build_trulens_recorder(r)\n",
    "\n",
    "    with tru_query_engine_recorder as recording:\n",
    "      for q in tqdm(questions):\n",
    "        r.query(q)\n",
    "\n",
    "    print(\"\\nFinished evaluation\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating:  BaseRag\n",
      "‚úÖ In Groundedness, input source will be set to __record__.app.retrieve.rets.collect() .\n",
      "‚úÖ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "‚úÖ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "‚úÖ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "‚úÖ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "‚úÖ In Context Relevance, input context will be set to __record__.app.retrieve.rets[:] .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 1/10 [00:04<00:38,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 2/10 [00:07<00:30,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 3/10 [00:09<00:20,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [00:11<00:16,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [00:14<00:12,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [00:16<00:09,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [00:18<00:07,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [00:22<00:05,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [00:25<00:02,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:27<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished evaluation\n",
      "\n",
      "Evaluating:  SentenceRetrievalRag\n",
      "‚úÖ In Groundedness, input source will be set to __record__.app.retrieve.rets.collect() .\n",
      "‚úÖ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "‚úÖ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "‚úÖ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "‚úÖ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "‚úÖ In Context Relevance, input context will be set to __record__.app.retrieve.rets[:] .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 1/10 [00:03<00:31,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 2/10 [00:07<00:29,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 3/10 [00:09<00:19,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [00:11<00:15,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [00:13<00:11,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [00:15<00:09,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [00:18<00:07,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [00:21<00:05,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [00:24<00:02,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:27<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished evaluation\n",
      "\n",
      "Evaluating:  AutomergingRetrievalRag\n",
      "‚úÖ In Groundedness, input source will be set to __record__.app.retrieve.rets.collect() .\n",
      "‚úÖ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "‚úÖ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "‚úÖ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "‚úÖ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "‚úÖ In Context Relevance, input context will be set to __record__.app.retrieve.rets[:] .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 1/10 [00:03<00:31,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 2/10 [00:07<00:28,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 3/10 [00:08<00:19,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [00:11<00:15,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [00:12<00:11,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [00:14<00:08,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [00:16<00:06,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [00:19<00:04,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [00:21<00:02,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:24<00:00,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished evaluation\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_rags(rags_for_eval, eval_questions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_name</th>\n",
       "      <th>app_version</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">RAG</th>\n",
       "      <th>base</th>\n",
       "      <td>0.894643</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.761111</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaseRag</th>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AutomergingRetrievalRag</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.000105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SentenceRetrievalRag</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Groundedness  Answer Relevance  \\\n",
       "app_name app_version                                               \n",
       "RAG      base                         0.894643          0.873333   \n",
       "         BaseRag                      0.844444          0.870000   \n",
       "         AutomergingRetrievalRag           NaN          0.880000   \n",
       "         SentenceRetrievalRag              NaN          0.870000   \n",
       "\n",
       "                                  Context Relevance  latency  total_cost  \n",
       "app_name app_version                                                      \n",
       "RAG      base                              0.761111      1.9    0.000098  \n",
       "         BaseRag                           0.729167      1.7    0.000085  \n",
       "         AutomergingRetrievalRag                NaN      1.7    0.000105  \n",
       "         SentenceRetrievalRag                   NaN      1.7    0.000109  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.get_leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents from vector store...\n",
      "Returning only text...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(response='El aprendizaje supervisado es un tipo de aprendizaje en el que los algoritmos generan modelos que pueden ser utilizados para predecir el valor de una variable, incluso cuando no se tiene el valor de la instancia buscada. Esto significa que estos modelos son capaces de hacer predicciones sobre nuevos ejemplos que se introducen en el sistema.', source_nodes=[NodeWithScore(node=TextNode(id_='a8cbd569-2942-4d94-934c-f571867d5ffd', embedding=[-0.00626267586, -0.0311642569, -0.00818880461, 0.0153535437, 0.00272112875, -0.00279599545, 0.0371277332, 0.0376591384, 0.0113066686, 0.0112052746, -0.0398028, -0.0574921593, -2.93830799e-05, 0.0146975098, 0.00277782325, 0.0401487537, 0.00972822122, -0.0197916646, 0.00326209376, -0.0310757346, -0.0319102481, 0.0169151835, 0.0433027372, 0.0236665048, -0.00628763251, -0.0169521645, 0.0160516016, -0.000796318753, -0.00886473, 0.0494747274, 0.0162876081, -0.024602, 0.0115180025, 0.0087354416, -0.0362080447, -0.00861438923, -0.0170659013, -0.0445275754, -0.00955688208, 0.0179261826, 0.0019399554, -0.0209745225, 0.0210694652, -0.0653981417, 0.0281927269, 0.00615199143, -0.0314906314, -0.0261430871, -0.00609776936, -0.0286764074, 0.0174257047, -0.0121886693, 0.0769601166, -0.048169639, 0.00100366748, 0.0371966586, 0.00285776309, -0.0177665036, -0.0337758586, 0.0047154869, -0.0365122892, -0.0207108166, -0.0340886489, 0.0222843289, 0.0313253626, -0.0104444772, -0.0290688854, 0.0360393748, -0.0273809116, -0.0290048197, 0.0498189256, 0.0115057137, -0.0477608889, 0.0393128507, -0.0490836687, 0.0374453291, -0.0552977324, -0.00220166426, -0.0639356896, 0.045514483, -0.0326690152, -0.0109624695, -0.00316005084, 0.011141506, -0.00593452295, -0.00768118352, 0.00679291179, 0.00436061202, 0.0261388514, 0.00196172786, -0.0206967313, 0.0104235513, 0.0384962857, -0.0677209795, -0.0222798493, -0.0207857173, -0.0228671096, -0.0044099139, 0.0270689987, 0.00922998134, 0.0103024123, 0.0114591457, 0.00474770367, -0.000231723228, 0.0419500694, -0.0316972509, 0.00113956816, 0.0129602617, -0.00980571751, -0.0341230631, 0.0114364699, 0.0159344785, -0.00347034307, 0.0287663359, -0.027459031, -0.00829821452, 0.0293648802, -0.0303200353, 0.00446047029, 0.00513391057, 0.00829459354, 0.0364973806, 0.0992069468, -0.0269380603, -0.0223024581, -0.0504364781, -0.0227282234, 0.024341289, 0.001308062, -0.024154393, -0.0161165148, 0.0766088143, -0.0178428832, 0.00109887542, -0.0502995253, -0.0349722877, -0.00946108438, -0.0158162136, -0.0469127372, -0.00804734, 0.0797661, 0.00197248952, -0.0348918438, -0.0142845735, 0.0709576234, -0.0394543596, 0.0342577063, 0.00704321917, 0.0220629107, -0.0207680184, -0.0272953957, 0.0273735393, -0.0208652988, -0.00272683776, 0.0367700644, -0.00944462605, -0.0483916588, -0.0182907544, -0.0141201383, 0.0322759971, -0.00337481871, -0.0186966565, 0.00268978, 0.0458747968, 0.0253977515, -0.00321208267, 0.0022924908, 0.0847309455, -0.0101160072, -0.00261223223, 0.00874490663, -0.0170420576, -0.00123484805, -0.0192830358, 0.0141057577, 0.0201059896, 0.0774658918, 0.0197746865, 0.0241850037, -0.0264995098, 0.0260868985, -0.0016915272, 0.00830809865, -0.043583665, -0.0141144283, 0.0151241142, -0.0229690894, 0.00292198476, 0.0126489019, -0.0287002791, -0.0225100536, -0.0354144275, 0.0493810438, 0.0035271456, 0.0160058849, -0.0341730639, 0.010495971, 0.00943640433, 0.0281669348, -0.041435156, -0.0106861219, 0.0413693562, -0.0326580741, -0.0158555117, -0.0529174171, 0.0122910179, -0.0272685383, -0.0282703899, 0.0267159045, -0.00877116155, 0.0661056787, 0.0304713231, 0.00733909663, 0.00719456887, -0.0240175072, -0.0100470381, -0.0199697819, 0.0484752543, -0.0103301806, -0.0438126437, -0.00317060226, 0.0406363718, 0.00597665599, 0.0261561666, 0.0185113493, -0.016608119, 0.00817773771, 0.0167195145, 0.025708247, 0.0332015902, 0.0387382768, 0.0311966818, -0.0385282487, -0.00552546792, 0.0346935838, -0.0536775589, -0.0505046807, 0.0315037593, 0.046373114, 0.0140012065, -0.00781201199, -0.0364897177, -0.00741416169, -0.0295247156, -0.0615170561, -0.00547077693, -0.0304618925, -0.0339020453, -0.0256894287, 0.00606951676, 0.0295588579, 0.0287672803, -0.0420420468, 0.00747671351, -0.020992646, 0.0200365912, 0.0118194083, -0.0295868907, -0.051339291, -0.0160042699, 0.0155426487, 0.0294100326, 0.0222657751, -0.0115975551, 0.0365087613, -0.00396932, 0.0273612011, -0.0126269488, -0.00484415097, 0.020926021, -0.00468243659, -0.00188377185, 0.00347743114, -0.0197015814, -0.0124136256, -0.0010691958, -0.0770792291, 0.0264446083, 0.145004377, 0.00771712558, -0.0563566759, -0.0175971072, 0.00594278285, 0.00493465969, 0.0692154616, -0.0400005169, -0.0457257517, 0.00737275369, -0.00256502419, -0.0387016162, 0.000769554114, 0.00910997577, 0.0377903059, -0.0177869, -0.0107534239, -0.0296981931, 0.00665167207, -0.139497429, -0.0161043517, 0.0121335248, -0.0589581542, 0.0074378862, 0.0122403735, -0.0253698789, 0.00799078681, -0.029001262, 0.0408878177, 0.000463839329, -0.0396024771, 0.00878740568, 0.00992891937, 0.041103594, 0.0123960786, -0.0205109529, 0.0113127381, -0.0233682804, -0.00773651153, 0.019668879, -0.0361085, 0.0257106069, -0.0197946746, -0.00528184604, -0.0137601513, 0.0380763, 0.0102288714, -0.0170721523, -0.0267652273, 0.0128168203, 0.023644492, -0.00028870994, -0.000193358632, 0.0383483022, 0.0140411993, -0.0106191365, -0.0197521076, 0.0354089513, -0.0143829305, 0.00519795343, 0.0604067, -0.0380174555, 0.0366544127, -0.0291478503, 0.0424953811, 0.0448394269, 0.030436676, -0.00741866371, 0.0389224812, 0.000129390683, -0.00934023317, 0.00229699654, 0.00479078852, -0.0557880029, 0.0272580162, 0.0258156154, 0.0277485475, -0.0126728471, 0.0165403783, -0.0195177458, -0.089185, -0.00247664144, -0.0479700826, -0.018151436, -0.00490189251, 0.0600500479, 0.00306413718, 0.0390352458, -0.050425984, 0.0222482942, -0.010875091, -0.0118490523, 0.00142221712, -0.0244448408, -0.00852005556, 0.0363044962, -0.0266620591, 0.0206341017, -0.0779697075, 0.000824680843, -0.0207028408, -0.0078469906, 0.00449508289, 0.00764811, -0.000506634184, 0.0151069397, -0.0335980915, 0.0110162366, 0.233440548, -0.0170353632, -0.0211181901, -0.0165306162, -0.00303638843, 0.0422036834, 0.0116754258, -0.00105818198, 0.0249314141, -0.0198430289, 0.0137342615, 0.0266158469, -0.0203274768, 0.0156669468, -0.0215611327, 0.0266681314, -0.0512662567, 0.0072018, 0.0434532575, 0.00217908761, 0.030559577, 0.0322886817, 0.0544287078, -0.000285206042, -0.0798184052, 0.0382505, 0.0190373622, -0.0291051213, -0.00870999135, 0.0073302635, -0.00649981899, 0.0154576395, 0.0265555736, -0.0302769449, -0.0256539453, -0.0417823493, 0.00559645379, -0.00519871153, 0.0398226306, 0.0334548876, 0.00309928297, 0.0248411, -0.0279417541, 0.0357109085, 0.0268243626, -0.00625660736, 0.0247287489, 0.017694125, -0.0098390514, -0.0340935402, -0.0349544287, -0.0553436875, -0.0158065651, -0.00295912288, -0.00152486516, 0.0261140149, -0.015467315, 0.0825186819, 0.0100478204, 0.0150110032, 0.0299515966, -0.00158015883, 0.00841161, -0.0119443852, 0.0155969243, -0.0196061824, -0.0268155672, -0.0303790644, 0.0465452261, 0.00799454469, 0.0172393601, 0.0463110916, 0.0081235012, -0.0380386636, 0.00771115627, 0.0045190067, 0.048334, 0.0196046196, -0.0340675, -0.0389512405, 0.0107591851, -0.0189077929, 0.000762195559, -0.0154592879, -0.000852804, -0.0533277579, -0.0286148507, 0.0677295476, -0.0341837667, 0.000841667817, -0.0312046986, -0.0109412046, 0.0131927431, 0.0224698707, -0.00165977504, 0.0124736587, 0.0139322644, -0.0108446479, -0.0118671106, 0.0584896319, -0.0178746469, -0.000916224206, 0.00917262677, 0.00113395869, 0.0229490604, -0.0404665358, 0.00854497682, 0.0139604332, -0.0187164582, 0.040448986, -0.0140821971, 0.00769349188, -0.00749080488, -0.0423273258, 0.00533929933, 0.0494029671, -0.03535017, 0.00194910774, 0.00596878, -0.0439753644, -0.064493008, 0.0384211391, -0.00458558323, 0.0644054264, -0.000213225, -0.0241866112, -0.0347090773, 0.0205317754, -0.00686461246, 0.0111239422, 0.0392901376, 0.00134860503, 0.00051358965, 0.034159489, 0.00958360638, 0.012172807, -0.0137905907, -0.026293885, 0.0311695151, 0.0200044606, -0.022916751, 0.0182098933, 0.0137364473, 0.0165697131, 0.0436752476, 0.0586928539, 0.0168411825, 0.00469473796, -0.0312622562, 0.0190095268, -0.0110514266, -0.0256820377, 0.0285094362, -0.0245376378, -0.031809371, -0.094577685, -0.0262433086, -0.0438504517, 0.0109620802, -0.0227224845, 0.00788016897, -0.00823380426, -0.0140187461, 0.032350447, -0.0230036117, 0.0472185835, 0.0102258623, 0.0309765749, -0.045977544, -0.0308255535, 0.0210941061, -0.0137138134, 0.00313104689, 0.00070858479, -0.0153014287, 0.0213761497, -0.00208569621, -0.00648602, -0.00968341157, -0.0600651875, 0.0170238093, 0.0230266135, 0.0220517293, 0.00164184032, -0.000912704098, -0.036985565, 0.0301782973, -0.00787876, -0.0140136201, 0.0136988834, -0.0160506461, 0.0613763966, -0.035945341, -0.00986560527, -0.00587140163, 0.045496773, 0.0842919871, -0.00938710291, 0.000446040271, -0.0329364911, -0.00709759817, -0.0285864249, 0.00437355554, -0.0247430243, -0.0215742793, 0.00769029092, -0.0231401231, 0.045083005, -0.0186137911, 0.0218991246, 0.00618192973, 0.00650496, -0.0522414967, 0.0199748091, 0.00196072808, -0.0269844066, 0.0409701355, -0.0181024019, -0.0276106261, -0.0228218921, 0.0094718663, 0.0314486176, 0.0207782462, -0.0484729223, -0.0672761872, 0.0389832109, 0.0135302721, 0.00651746895, -0.0226827227, 0.0218687523, -0.00878735166, 0.0224210396, 0.00185333646, 0.00454943394, -0.0242797546, -0.00555015914, 0.00784415659, 0.0192802157, -0.0157286357, -0.0510530584, 0.00287775928, 0.00705802953, -0.0220905524, 0.00744271232, -0.0270296838, -0.0400923528, -0.0586440787, 0.0137697374, 0.0122839483, 0.00455891434, 0.0236440115, 0.0117945978, 0.0240376107, -0.00409863563, 0.00577045931, 0.0106333513, 0.0106055913, -0.00494292658, -0.00496160099, -0.0142017826, -0.025441071, 0.016210597, 0.0160247292, -0.00422771228, 0.0221657641, -0.0347162969, -0.00247482071, 0.0221752264, -0.0301225614, -0.0603954606, -0.0263540484, 0.0244337339, -0.0102693951, -0.056149438, -0.000345388456, -0.0174135976, -0.0216717962, -0.0057715578, 0.0284045152, 0.0156172104, -0.062710762, 0.0555288047, -0.00548176793, 0.0398401693, -0.023075318, -0.0200567096, 0.0490268506, -0.0332331248, 0.0169243608, -0.0504084527, 0.0482713841, 0.0392217673, 0.00816084724, 0.0439720191, 0.0276286639, 0.0275278687, -0.0228163134, 0.058795128, -0.0607973821, -0.0118857361, -0.0345601067, -0.00738700805, 5.38496897e-05, 0.0392771251, -0.0144177517, 0.00953424349, 0.0157340672, -0.0717903599, -0.011767, 0.0252320487, -0.0226240307, -0.0341894254, 0.00270886929, 0.0143758077, -0.0186795741, -0.00905272, 0.0735287666, -0.0439601578, 0.00825682748, 0.0314142741, -0.0145547949, -0.0117901452, -0.0495361201, -0.0115268156, -0.0386999324, 0.0218765717, -0.0329402909, -0.0150204049, 0.0083113648, -0.0367020331, -0.0218967386, -0.0494758077, 0.0152034331, 0.00190515292, 0.0412528142, -0.00834480952, 0.018261971, -0.0291627608, 0.0350156501, -0.00770452479, 0.0586954877, -0.0285566263, 0.0657970384, -0.026625216, 0.020958107, 0.0181394871, 0.00150763674, -0.00935502909, 0.00587261934, -0.00923771318, 0.0128728198, 0.00871783, 0.000978332362, -0.0155772949, 0.026616415, 0.00924831908, -0.0279317498, 0.0375785232, 0.027302295, 0.017029658, -0.0433929451, 0.0347262286, 0.0264928509, -0.0214064606, 0.0157655142, 0.0271083824, 0.00662737479, -0.0415304676, 0.0165087376, -0.0179897659, -0.0149614615, -0.00126271951, 0.0450000316, -0.0588565581, 0.00299013755, 0.032098297, -0.0759429, 0.0478145, 0.0470500328, 0.00706480956, -0.0180568788, -0.039143648, -0.0231668614, 0.00304724812, 0.0105658891, -0.0526849665, -0.0397094563, 0.0232963227, 0.0090785427, 0.0117444843, -0.00581981475, 0.0214589, -0.0148160839, 0.0126701286, -0.113827936, -0.0241491552, -0.0208124779, 0.0417888276, -0.0311271343, -0.000639773847, 0.0181178581, -0.041527573, -0.0198402368, -0.0629821569, -0.0195325091, 0.0315527767, -0.0162843391, -0.0186963137, 0.0241064318, 0.0657142922, -0.0153524196, 0.00523639284, -0.0106963636, 0.0610795394, -0.00126802991, 0.000515495, 0.0439884886, -0.0540494919, -0.0123590333, -0.0565503202, -0.0158176348, 0.0409735329, 0.00826047268, -0.0819823816, 0.0100978566, -0.0431838371, 0.0399300456, -0.000656340737, -0.0421054401, 0.00288896868, -0.0268654693, -0.0089006722, 0.0260455571, -0.00888232235, 0.0137829408, 0.0122927651, -0.0105276452, 0.0106850257, -0.0174987894, 0.0927210823, -0.00982138701, -0.0142837036, 0.00537053635, -0.0219071042, -0.0297826175, -0.0184941571, -0.0513769537, 0.00287509779, -0.00853167195, -0.0118614128, -0.0454660803, 0.00484056864, -0.0185464416, 0.055469241, -0.0250609275, 0.0443825759, -0.0442933589, 0.0146289058, -0.00551590882, 0.00995500293, -0.0645310357, -0.00888451654, 0.000764846336, -0.0277400576, 0.0120887524, 0.0543887056, -0.0114207743, -0.0309090465, 0.0178622548, -0.00576764811, 0.00749804592, -0.00379139115, -0.020107083, -0.00306407781, 0.0161114391, -0.0319591835, -0.041025959, -0.0222895555, 0.0329994634, -0.027481515, -0.0242654644, -0.037467353, -0.0987488404, -0.0216237064, -0.0527716801, -0.0220138412, 0.00523782615, 0.0169316065, -0.0502852574, -0.0111596985, 0.0175765324, 0.040688809, -0.00165823707, -0.0123131266, -0.00912325364, 0.00865550153, 0.0143661266, 0.0355630331, -0.0136209903, 0.0135158142, -0.0123098101, 0.0108029526, -0.00373054412, -0.0141809462, 0.00154368463, -0.0108348941, -0.0117020747, -0.00975057483, -0.0648630038, -0.00359961484, 0.0186142363, 0.0426819623, 0.0115511362, 0.0259994343, 0.0281825531, -0.0268949941, -0.00899300352, -0.00417221291, 0.0138851423, 0.074187912, 0.0265425351, 0.00065390591, 0.0550471246, -0.0548583753, 0.0210199747, -0.057997033, -0.00536181824, -0.0594915673, 0.0133574009, -0.0120678395, -0.0424387082, 0.0338198133, -0.00845915359, -0.0413198173, -0.0489117876, 0.00702658854, -0.0114600137, -0.0309749767, 0.000773351872, -0.0299046282, 0.0296963658, 0.00764437765, -0.0297746602, -0.0391265973, 0.0235326272, -0.0187027734, -0.00225160271, 0.0689419881, -0.00188885373, 0.03209088, -0.0164940655, 0.0184221268, 0.0387268923, 0.0440637507, 0.0140170576, -0.00389497867, -0.0137698865, 0.012646405, -0.0248637013, -0.0210651, -0.0453344211, 0.0079783164, -0.0222234968, 0.0516993217, -0.000212305298, 0.0733428299, -0.0344010517, -0.0184154492, 0.00721147656, -0.0255065206, -0.0360572264, 0.0475144759, 0.000873266195, -0.055185724, 0.0237397738, 0.0191391129, 0.0546349101, 0.0312374644, 0.0254473668, -0.000364289765, -0.0377488844, 0.029258376, 0.0533812158, -0.0169685464, 0.0221681241, -0.031506028, 0.00419963663, -0.0174750034, 0.0167169627, 0.0345235616, 0.0457621664, 0.0101295114, 0.00682093203, 0.0371021815, -0.0346335769, 0.00215794891, 0.013617577, -0.0087152347, -0.0192454066, -0.016027309, 0.00969483797, -0.0469944, -0.008255261, 0.00355207, -0.0068097976, -0.0132158725, -0.00943412352, 0.00753264688, 0.000614174642, -0.038182497, 0.00580748124, 0.0220723413, 0.0106359348, 0.00491870195, -0.00107442867, 0.0320794657, -0.014147222, -0.0101836612, -0.0256428476, -0.0145909898, 0.0165856425, 0.0221203696, 0.0174484625, 0.00607061805, -0.0161666889, -0.0396601483, 0.00512543647, 0.0360490941, -0.0139003163, 0.0372634493, 0.00885523297, 0.0364794657, -0.0018282797, -0.0109238606, 0.0454703495, -0.0125916777, 0.0803439394, 0.00514545105], metadata={'chunk_type': 'para', 'title': 'Tipos de aprendizaje.pdf', 'window': 'Objetivos > 2.  Clasificaci√≥n de los tipos de aprendizaje > 2.1.  Aprendizaje Supervisado\\nLos algoritmos supervisados dan lugar a modelos que son utilizables en la pr√°ctica para predecir el valor de una variable en ausencia del valor de la instancia buscada, es decir, para nuevos ejemplos que van entrando en nuestro sistema.\\n Por ejemplo, un sistema de diagn√≥stico m√©dico de una enfermedad utilizar√≠a un m√©todo supervisado, ya que recibe como entrada un conjunto de pacientes que tienen o no tienen una determinada enfermedad en funci√≥n de sus s√≠ntomas, y se construye un modelo que es capaz de predecir si un nuevo paciente tendr√° la enfermedad o no de acuerdo con sus s√≠ntomas.', 'text': 'Aprendizaje Supervisado\\nLos algoritmos supervisados dan lugar a modelos que son utilizables en la pr√°ctica para predecir el valor de una variable en ausencia del valor de la instancia buscada, es decir, para nuevos ejemplos que van entrando en nuestro sistema.\\n'}, excluded_embed_metadata_keys=['window', 'text'], excluded_llm_metadata_keys=['window', 'text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='007e4fec-29a0-4fb9-973c-eab08f7b36cd', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'chunk_type': 'para', 'title': 'Tipos de aprendizaje.pdf'}, hash='e67089e02f55ba3e03e42a92b905e3b620feb049d53342fbc3bcc5447eff781f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8b47e41f-8929-405c-ba02-8fafae239077', node_type=<ObjectType.TEXT: '1'>, metadata={'chunk_type': 'para', 'title': 'Tipos de aprendizaje.pdf', 'window': 'Objetivos > 2.  Clasificaci√≥n de los tipos de aprendizaje > 2.1.  Aprendizaje Supervisado\\nLos algoritmos supervisados dan lugar a modelos que son utilizables en la pr√°ctica para predecir el valor de una variable en ausencia del valor de la instancia buscada, es decir, para nuevos ejemplos que van entrando en nuestro sistema.\\n Por ejemplo, un sistema de diagn√≥stico m√©dico de una enfermedad utilizar√≠a un m√©todo supervisado, ya que recibe como entrada un conjunto de pacientes que tienen o no tienen una determinada enfermedad en funci√≥n de sus s√≠ntomas, y se construye un modelo que es capaz de predecir si un nuevo paciente tendr√° la enfermedad o no de acuerdo con sus s√≠ntomas.', 'text': 'Clasificaci√≥n de los tipos de aprendizaje > 2.1. '}, hash='50f6be58d078a5cde4ce66f82633ae83f338f2abdaa18a81a4348964a35399d9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='272cad16-d70c-43f5-a3af-e5ab6d2d9b4c', node_type=<ObjectType.TEXT: '1'>, metadata={'window': 'Objetivos > 2.  Clasificaci√≥n de los tipos de aprendizaje > 2.1.  Aprendizaje Supervisado\\nLos algoritmos supervisados dan lugar a modelos que son utilizables en la pr√°ctica para predecir el valor de una variable en ausencia del valor de la instancia buscada, es decir, para nuevos ejemplos que van entrando en nuestro sistema.\\n Por ejemplo, un sistema de diagn√≥stico m√©dico de una enfermedad utilizar√≠a un m√©todo supervisado, ya que recibe como entrada un conjunto de pacientes que tienen o no tienen una determinada enfermedad en funci√≥n de sus s√≠ntomas, y se construye un modelo que es capaz de predecir si un nuevo paciente tendr√° la enfermedad o no de acuerdo con sus s√≠ntomas.', 'text': 'Por ejemplo, un sistema de diagn√≥stico m√©dico de una enfermedad utilizar√≠a un m√©todo supervisado, ya que recibe como entrada un conjunto de pacientes que tienen o no tienen una determinada enfermedad en funci√≥n de sus s√≠ntomas, y se construye un modelo que es capaz de predecir si un nuevo paciente tendr√° la enfermedad o no de acuerdo con sus s√≠ntomas.'}, hash='5c3dc99f6691c61d33e0212b03e480106a8b1c117d22d0e6fee0a6772c47f12c')}, text='Aprendizaje Supervisado\\nLos algoritmos supervisados dan lugar a modelos que son utilizables en la pr√°ctica para predecir el valor de una variable en ausencia del valor de la instancia buscada, es decir, para nuevos ejemplos que van entrando en nuestro sistema.\\n', mimetype='text/plain', start_char_idx=64, end_char_idx=325, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.594116688)], metadata={'a8cbd569-2942-4d94-934c-f571867d5ffd': {'chunk_type': 'para', 'title': 'Tipos de aprendizaje.pdf', 'window': 'Objetivos > 2.  Clasificaci√≥n de los tipos de aprendizaje > 2.1.  Aprendizaje Supervisado\\nLos algoritmos supervisados dan lugar a modelos que son utilizables en la pr√°ctica para predecir el valor de una variable en ausencia del valor de la instancia buscada, es decir, para nuevos ejemplos que van entrando en nuestro sistema.\\n Por ejemplo, un sistema de diagn√≥stico m√©dico de una enfermedad utilizar√≠a un m√©todo supervisado, ya que recibe como entrada un conjunto de pacientes que tienen o no tienen una determinada enfermedad en funci√≥n de sus s√≠ntomas, y se construye un modelo que es capaz de predecir si un nuevo paciente tendr√° la enfermedad o no de acuerdo con sus s√≠ntomas.', 'text': 'Aprendizaje Supervisado\\nLos algoritmos supervisados dan lugar a modelos que son utilizables en la pr√°ctica para predecir el valor de una variable en ausencia del valor de la instancia buscada, es decir, para nuevos ejemplos que van entrando en nuestro sistema.\\n'}})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rags_for_eval[0].query(\"Qu√© es el aprendizaje supervisado?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n",
      "Dashboard already running at path:   Network URL: http://172.16.30.1:53459\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "run_dashboard(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".eval_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
